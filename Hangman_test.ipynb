{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version: 3.6.4 (default, Mar  9 2018, 23:15:03) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n",
      "TensorFlow version: 1.6.0\n",
      "NumPy version: 1.14.2\n",
      "Pandas version: 0.22.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os,shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import collections\n",
    "print('''\n",
    "Python version: {}\n",
    "TensorFlow version: {}\n",
    "NumPy version: {}\n",
    "Pandas version: {}\n",
    "'''.format(sys.version, tf.__version__, np.__version__, pd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "----------------Readind trained model---------------------------------\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "----------------Loading trained model---------------------------------\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The MAX_WORD_LENGTH is the max word length from 250,000 dictionary words\n",
    "MAX_WORD_LENGTH=29\n",
    "N_WORDS = 27*MAX_WORD_LENGTH\n",
    "N_GUESSED=26\n",
    "N_CLASSES = 26\n",
    "HIDDEN_SIZE4 = 300\n",
    "HIDDEN_SIZE1 = 150\n",
    "HIDDEN_SIZE2 = 80\n",
    "HIDDEN_SIZE3=HIDDEN_SIZE2+N_GUESSED\n",
    "# inputs       \n",
    "x_words = tf.placeholder(tf.float32, [None,N_WORDS], name=\"words\")\n",
    "x_guessed=tf.placeholder(tf.float32, [None,N_GUESSED], name=\"guessed\")\n",
    "y_label = tf.placeholder(tf.float32, [None,N_CLASSES], name=\"labels\")\n",
    "# hidden layer1\n",
    "W4 = tf.Variable(tf.truncated_normal([N_WORDS, HIDDEN_SIZE4],stddev=N_WORDS**-0.5),name=\"W4\")\n",
    "b4 = tf.Variable(tf.zeros([HIDDEN_SIZE4]),name=\"b4\")\n",
    "hidden4 = tf.nn.relu(tf.matmul(x_words, W4) + b4)\n",
    "# hidden layer2\n",
    "W1 = tf.Variable(tf.truncated_normal([HIDDEN_SIZE4, HIDDEN_SIZE1],stddev=HIDDEN_SIZE4**-0.5),name=\"W1\")\n",
    "b1 = tf.Variable(tf.zeros([HIDDEN_SIZE1]),name=\"b1\")\n",
    "hidden1 = tf.nn.sigmoid(tf.matmul(hidden4, W1) + b1)\n",
    "# hidden layer3\n",
    "W2 = tf.Variable(tf.truncated_normal([HIDDEN_SIZE1, HIDDEN_SIZE2],stddev=HIDDEN_SIZE1**-0.5),name=\"W2\")\n",
    "b2 = tf.Variable(tf.zeros([HIDDEN_SIZE2]),name=\"b2\")\n",
    "hidden2 = tf.nn.sigmoid(tf.matmul(hidden1, W2) + b2)\n",
    "# output layer4\n",
    "W3 = tf.Variable(tf.truncated_normal([HIDDEN_SIZE3, N_CLASSES],stddev=HIDDEN_SIZE3**-0.5),name=\"W3\")\n",
    "b3 = tf.Variable(tf.zeros([N_CLASSES]),name=\"b3\")\n",
    "y = tf.matmul(tf.concat([hidden2,x_guessed],1), W3) + b3\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_label))\n",
    "# prediction function\n",
    "pred=tf.reduce_mean(tf.argmax(y,1))\n",
    "# optimizer\n",
    "sgd = tf.train.MomentumOptimizer(0.5,0.1).minimize(loss)\n",
    "#--------------------------------------------\n",
    "#\n",
    "#    LOAD MODELS\n",
    "#\n",
    "#--------------------------------------------\n",
    "folder = './hangman_model'\n",
    "LOADED=False\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "sess=tf.Session()\n",
    "#Initialization\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# load trained weights\n",
    "if os.path.exists('./hangman_model/W1.npy') and not LOADED:\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('----------------Readind trained model---------------------------------')\n",
    "    print('---------------------------------------------------------------------')       \n",
    "    #read trained weights anb biases\n",
    "    W1_np=np.load('./hangman_model/W1.npy')\n",
    "    W2_np=np.load('./hangman_model/W2.npy')\n",
    "    W3_np=np.load('./hangman_model/W3.npy')\n",
    "    W4_np=np.load('./hangman_model/W4.npy')\n",
    "    b1_np=np.load('./hangman_model/b1.npy')\n",
    "    b2_np=np.load('./hangman_model/b2.npy')\n",
    "    b3_np=np.load('./hangman_model/b3.npy')\n",
    "    b4_np=np.load('./hangman_model/b4.npy')\n",
    "    #restore trained weights and biases\n",
    "    if  W1.shape==W1_np.shape:\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print('----------------Loading trained model---------------------------------')\n",
    "        print('---------------------------------------------------------------------')\n",
    "        sess.run(tf.assign(W1, W1_np))\n",
    "        sess.run(tf.assign(W2, W2_np))\n",
    "        sess.run(tf.assign(W3, W3_np))\n",
    "        sess.run(tf.assign(W4, W4_np))\n",
    "        sess.run(tf.assign(b1, b1_np))\n",
    "        sess.run(tf.assign(b2, b2_np))\n",
    "        sess.run(tf.assign(b3, b3_np))\n",
    "        sess.run(tf.assign(b4, b4_np))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the game player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HangmanPlayer:\n",
    "    def __init__(self, word, model, lives=11):\n",
    "        self.original_word = word\n",
    "        self.full_word = [ord(i)-97 for i in word]\n",
    "        self.letters_guessed = set([])\n",
    "        self.letters_remaining = set(self.full_word)\n",
    "        self.lives_left = lives\n",
    "        self.obscured_words_seen = []\n",
    "        self.letters_previously_guessed = []\n",
    "        self.guesses = []\n",
    "        self.correct_responses = []\n",
    "        self.z = model\n",
    "        return\n",
    "    \n",
    "    def encode_obscured_word(self):\n",
    "        word = [i if i in self.letters_guessed else 26 for i in self.full_word]\n",
    "        obscured_word = np.zeros((MAX_WORD_LENGTH, 27), dtype=np.float32)\n",
    "        for i, j in enumerate(word):\n",
    "            obscured_word[i, j] = 1\n",
    "        return(obscured_word.flatten())\n",
    "    \n",
    "    def encode_guess(self, guess):\n",
    "        encoded_guess = np.zeros(26, dtype=np.float32)\n",
    "        encoded_guess[guess] = 1\n",
    "        return(encoded_guess)\n",
    "\n",
    "    def encode_previous_guesses(self):\n",
    "        # Create a 1 x 26 vector where 1s indicate that the letter was previously guessed\n",
    "        guess = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_guessed:\n",
    "            guess[i] = 1\n",
    "        return(guess)\n",
    "    \n",
    "    def encode_correct_responses(self):\n",
    "        # To be used with cross_entropy_with_softmax, this vector must be normalized\n",
    "        response = np.zeros(26, dtype=np.float32)\n",
    "        for i in self.letters_remaining:\n",
    "            response[i] = 1.0\n",
    "        response /= response.sum()\n",
    "        return(response)\n",
    "    \n",
    "    def store_guess_and_result(self, guess):\n",
    "        # Record what the model saw as input: an obscured word and a list of previously-guessed letters\n",
    "        self.obscured_words_seen.append(self.encode_obscured_word())\n",
    "        self.letters_previously_guessed.append(self.encode_previous_guesses())\n",
    "        \n",
    "        # Record the letter that the model guessed, and add that guess to the list of previous guesses\n",
    "        self.guesses.append(guess)\n",
    "        self.letters_guessed.add(guess)\n",
    "        \n",
    "        # Store the \"correct responses\"\n",
    "        correct_responses = self.encode_correct_responses()\n",
    "        self.correct_responses.append(correct_responses)\n",
    "        \n",
    "        # Determine an appropriate reward, and reduce # of lives left if appropriate\n",
    "        if guess in self.letters_remaining:\n",
    "            self.letters_remaining.remove(guess)\n",
    "        \n",
    "        if self.correct_responses[-1][guess] < 0.00001:\n",
    "            self.lives_left -= 1\n",
    "        return\n",
    "                \n",
    "    def run(self):\n",
    "        while (self.lives_left > 0) and (len(self.letters_remaining) > 0):\n",
    "            x1=np.array([self.encode_obscured_word()])\n",
    "            x2=np.array([self.encode_previous_guesses()])\n",
    "            guess = self.z.run(pred,feed_dict={x_words: x1,x_guessed:x2})\n",
    "            \n",
    "            self.store_guess_and_result(guess)\n",
    "        \n",
    "        # Return the observations for use in training (both inputs, predictions, and losses)\n",
    "        return(self.obscured_words_seen,\n",
    "               self.letters_previously_guessed,\n",
    "               self.correct_responses,self.lives_left > 0)\n",
    "    \n",
    "    def evaluate_performance(self):\n",
    "        # Assumes that the run() method has already been called\n",
    "        ended_in_success = self.lives_left > 0\n",
    "        letters_in_word = set([i for i in self.original_word])\n",
    "        correct_guesses = len(letters_in_word) - len(self.letters_remaining)\n",
    "        incorrect_guesses = len(self.guesses) - correct_guesses\n",
    "        return(ended_in_success, correct_guesses, incorrect_guesses, letters_in_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1136 words\n"
     ]
    }
   ],
   "source": [
    "full_dictionary_location = \"words_250000_train.txt\"\n",
    "text_file = open(full_dictionary_location,\"r\")\n",
    "full_dictionary = text_file.read().splitlines()\n",
    "random.shuffle(full_dictionary)\n",
    "text_file.close()\n",
    "# define test data\n",
    "test_val_split_idx=int(len(full_dictionary) * 0.005)\n",
    "test_dictionary=full_dictionary[:test_val_split_idx]\n",
    "print('Training with {} words'.format(test_val_split_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(my_words, my_model):\n",
    "    results = []\n",
    "    for word in my_words:\n",
    "        my_player = HangmanPlayer(word, my_model)\n",
    "        _ = my_player.run()\n",
    "        results.append(my_player.evaluate_performance())\n",
    "    df = pd.DataFrame(results, columns=['won', 'num_correct', 'num_incorrect', 'letters'])\n",
    "    return(df)\n",
    "\n",
    "result_df = evaluate_model(test_dictionary, sess)\n",
    "print('Performance on the validation set:')\n",
    "print('- Averaged {:0.1f} correct and {:0.1f} incorrect guesses per game'.format(result_df['num_correct'].mean(),\n",
    "                                                                       result_df['num_incorrect'].mean()))\n",
    "print('- Won {:0.1f}% of games played'.format(100 * result_df['won'].sum() / len(result_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
